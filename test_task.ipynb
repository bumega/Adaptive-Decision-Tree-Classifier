{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка неполных данных в деревьях решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Цель работы\n",
    "Исследовать методы обработки пропущенных значений в табличных данных и реализовать модифицированное дерево решений, не игнорирующее наблюдени с пропусками. Провести сравнительный анализ предложенного метода с классическими деревьями решений и градиентным бустингом (XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Идея алгоритма\n",
    "Во время разбиения по признаку, который отсутствует у наблюдения, добавлять наблюдение в обе формируемые ветви. Из-за этого вместо точного ответа будет получаться ответ вероятностный (как именно выбрать итоговый класс остаётся на личное усмотрение)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задачи\n",
    "* Изучить существующие методы обработки неполных данных и типы пропусков.\n",
    "* Реализовать класс `AdaptiveDecisionTreeClassifier` для дерева решений с обработкой пропусков (в качестве критерия разбиения Gini или энтропия, входные данные числовые).\n",
    "* Провести сравнение предложенного метода с обычным деревом решений (`sklearn.tree.DecisionTreeClassifier`) и градиентным бустингом (`XGBoost`).\n",
    "* Использовать учебные наборы данных (например, [Iris](https://www.kaggle.com/datasets/himanshunakrani/iris-dataset), [Titanic](https://www.kaggle.com/datasets/yasserh/titanic-dataset), [Adult Income](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset), любые другие табличные наборы для классификации).\n",
    "* Оценить влияние пропусков на качество моделей, используя метрики (Accuracy, F1-score).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ожидаемые результаты\n",
    "* Теоретический обзор (краткое описание методов).\n",
    "* Код реализации дерева решений.\n",
    "* Графики / таблицы, демонстрирующие результаты сравнения.\n",
    "* Выводы о преимуществах и недостатках предложенного метода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Требования к реализации\n",
    "* Код должен быть написан на Python версии 3.9 и выше.\n",
    "* Рекомендуемые библиотеки: `numpy`, `pandas`, `scikit-learn`, `xgboost`, `matplotlib`).\n",
    "* Стиль кода соответствует PEP8.\n",
    "* Реализация дерева решений должна быть в виде отдельного класса с методами `fit`, `predict`.\n",
    "* Датасеты и код для экспериментов должны быть воспроизводимыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Заготовка класса:\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AdaptiveDecisionTreeClassifier:\n",
    "   def __init__(self, criterion: str = \"gini\", min_samples_split: int = 2, min_samples_leaf: int = 1):\n",
    "      pass\n",
    "\n",
    "   def fit(self, x: np.ndarray, y: np.array) -> \"AdaptiveDecisionTreeClassifier\":\n",
    "      pass\n",
    "\n",
    "   def predict(self, x: np.ndarray) -> np.array:\n",
    "      pass\n",
    "\n",
    "   def get_depth(self) -> int:\n",
    "      pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### найденные источники\n",
    "\n",
    "https://loginom.ru/blog/decision-tree-c45-2\n",
    "\n",
    "https://habr.com/ru/companies/productstar/articles/523044/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### имопрт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Модиффицированное дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion(ABC):\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def compute(cls, x: np.ndarray, y: np.ndarray, y_probs: np.array, \n",
    "               min_samples_leaf: int) -> tuple:\n",
    "        pass\n",
    "\n",
    "\n",
    "class CriterionGini:\n",
    "    @staticmethod\n",
    "    def gini(x_atr: np.ndarray, y: np.array, y_probs: np.array, min_samples_leaf: int) -> tuple:\n",
    "        '''finding the best threshold using gini for a specific attribute x_atr, \\\n",
    "            the target variable y, and y probabilities y_probs'''\n",
    "        x_nan_idx = np.isnan(x_atr.astype('float'))\n",
    "        x_atr_complete = x_atr[~x_nan_idx]\n",
    "        y_complete = y[~x_nan_idx]\n",
    "        y_complete_probs = y_probs[~x_nan_idx]\n",
    "        y_nan = y[x_nan_idx]\n",
    "        y_nan_probs = y_probs[x_nan_idx]\n",
    "        unique_atrs = np.sort(np.unique(x_atr_complete))\n",
    "        unique_anses = np.sort(np.unique(y))\n",
    "        \n",
    "        #if all answers are frome one class\n",
    "        if unique_anses.size < 2:\n",
    "            return None, 0.0\n",
    "\n",
    "        #processing data with complete attribute\n",
    "        sorted_complete_idx = np.argsort(x_atr_complete)\n",
    "        x_atr_sort_complete = x_atr_complete[sorted_complete_idx]\n",
    "        y_sort_complete = y_complete[sorted_complete_idx]\n",
    "\n",
    "        #all possible thresholds for attribute\n",
    "        thresholds = (unique_atrs[:-1] + unique_atrs[1:]) / 2\n",
    "        gini_min = 1.0\n",
    "        best_threshold = None\n",
    "\n",
    "        #finding best threshold\n",
    "        for threshold in thresholds:\n",
    "            #separating y\n",
    "            mask = x_atr_sort_complete > threshold\n",
    "            y_right = np.concatenate((y_sort_complete[mask], y_nan))\n",
    "            y_right_probs = np.concatenate((y_complete_probs[mask], y_nan_probs * np.mean(mask)))\n",
    "            y_left = np.concatenate((y_sort_complete[~mask], y_nan))\n",
    "            y_left_probs = np.concatenate((y_complete_probs[~mask], y_nan_probs * (1 - np.mean(mask))))\n",
    "            \n",
    "            total_left_weight = np.sum(y_left_probs)\n",
    "            total_right_weight = np.sum(y_right_probs)\n",
    "            \n",
    "            if total_left_weight < min_samples_leaf or total_right_weight < min_samples_leaf:\n",
    "                continue\n",
    "\n",
    "            #calculation left based on the probabilities of occurrence of y\n",
    "            left_counts = np.bincount(y_left, y_left_probs)\n",
    "            p_left = left_counts / total_left_weight\n",
    "            gini_left = 1 - np.sum(p_left ** 2)\n",
    "\n",
    "            #calculation right based on the probabilities of occurrence of y\n",
    "            right_counts = np.bincount(y_right, y_right_probs)\n",
    "            p_right = right_counts / total_right_weight\n",
    "            gini_right = 1 - np.sum(p_right ** 2)\n",
    "            \n",
    "            #calculating weighted gini\n",
    "            total_wight = total_left_weight + total_right_weight\n",
    "            gini_temp = (gini_left * total_left_weight + gini_right * total_right_weight) / total_wight\n",
    "\n",
    "            if gini_temp < gini_min:\n",
    "                gini_min = gini_temp\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_threshold, gini_min\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute(x: np.ndarray, y: np.ndarray, y_probs: np.array, min_samples_leaf: int) -> tuple:\n",
    "        '''finding best threshold with gini from all attributes'''\n",
    "        best_gini = 1.0\n",
    "        best_threshold = None\n",
    "        best_feature_idx = -1\n",
    "        prob_right = None\n",
    "\n",
    "        for feature_idx in range(x.shape[1]):\n",
    "            x_atr = x[:, feature_idx]\n",
    "            threshold_temp, gini_temp = CriterionGini.gini(x_atr, y, y_probs, min_samples_leaf)\n",
    "            if threshold_temp is None:\n",
    "                continue\n",
    "            if gini_temp < best_gini:\n",
    "                best_gini = gini_temp\n",
    "                best_threshold = threshold_temp\n",
    "                best_feature_idx = feature_idx\n",
    "                \n",
    "                #finding the probability of hitting the right branch\\\n",
    "                    # is necessary for future predictions\n",
    "                x_atr_complete = ~np.isnan(x_atr.astype('float'))\n",
    "                mask = x_atr_complete > best_threshold\n",
    "                prob_right = np.mean(mask)\n",
    "\n",
    "        return best_feature_idx, best_threshold, best_gini, prob_right\n",
    "\n",
    "\n",
    "class CriterionEntropy:\n",
    "    @staticmethod\n",
    "    def entropy(x_atr: np.ndarray, y: np.array, y_probs: np.array, min_samples_leaf: int) -> tuple:\n",
    "        '''finding the best threshold using entropy for a specific attribute x_atr, \\\n",
    "            the target variable y, and y probabilities y_probs'''\n",
    "        x_nan_idx = np.isnan(x_atr.astype('float'))\n",
    "        x_atr_complete = x_atr[~x_nan_idx]\n",
    "        y_complete = y[~x_nan_idx]\n",
    "        y_complete_probs = y_probs[~x_nan_idx]\n",
    "        y_nan = y[x_nan_idx]\n",
    "        y_nan_probs = y_probs[x_nan_idx]\n",
    "        unique_atrs = np.sort(np.unique(x_atr_complete))\n",
    "        unique_anses = np.sort(np.unique(y))\n",
    "        \n",
    "        #if all answers are frome one class\n",
    "        if unique_anses.size < 2:\n",
    "            return None, 0.0\n",
    "\n",
    "        #processing data with complete attribute\n",
    "        sorted_complete_idx = np.argsort(x_atr_complete)\n",
    "        x_atr_sort_complete = x_atr_complete[sorted_complete_idx]\n",
    "        y_sort_complete = y_complete[sorted_complete_idx]\n",
    "        y_sort_complete_probs = y_complete_probs[sorted_complete_idx]\n",
    "\n",
    "        #all possible thresholds for attribute\n",
    "        thresholds = (unique_atrs[:-1] + unique_atrs[1:]) / 2\n",
    "\n",
    "\n",
    "        #finding max possible entropy\n",
    "        parent_counts = np.bincount(y, weights=y_probs)\n",
    "        parent_total = np.sum(parent_counts)\n",
    "        p_parent = parent_counts / (parent_total + 1e-10)\n",
    "        parent_entropy = -np.sum(p_parent * np.log2(p_parent + 1e-10))\n",
    "        entropy_min = parent_entropy\n",
    "        best_threshold = None\n",
    "\n",
    "        #finding best threshold\n",
    "        for threshold in thresholds:\n",
    "            #separating y\n",
    "            mask = x_atr_sort_complete > threshold\n",
    "            y_right = np.concatenate((y_sort_complete[mask], y_nan))\n",
    "            y_right_probs = np.concatenate((y_sort_complete_probs[mask], y_nan_probs * np.mean(mask)))\n",
    "            y_left = np.concatenate((y_sort_complete[~mask], y_nan))\n",
    "            y_left_probs = np.concatenate((y_sort_complete_probs[~mask], y_nan_probs * (1 - np.mean(mask))))\n",
    "            \n",
    "            total_left = np.sum(y_left_probs)\n",
    "            total_right = np.sum(y_right_probs)\n",
    "            \n",
    "            if total_left < min_samples_leaf or total_right < min_samples_leaf:\n",
    "                continue\n",
    "\n",
    "            #calculation left based on the probabilities of occurrence of y\n",
    "            left_counts = np.bincount(y_left, weights=y_left_probs, minlength=unique_anses.size)\n",
    "            left_total = np.sum(left_counts)\n",
    "            p_left = left_counts / (left_total + 1e-10)\n",
    "            entropy_left = -np.sum(p_left * np.log2(p_left + 1e-10))\n",
    "\n",
    "            #calculation right based on the probabilities of occurrence of y\n",
    "            right_counts = np.bincount(y_right, weights=y_right_probs, minlength=unique_anses.size)\n",
    "            right_total = np.sum(right_counts)\n",
    "            p_right = right_counts / (right_total + 1e-10)\n",
    "            entropy_right = -np.sum(p_right * np.log2(p_right + 1e-10))\n",
    "\n",
    "            #calculating weighted entropy\n",
    "            total_weight = total_left + total_right\n",
    "            current_entropy = (entropy_left * total_left + entropy_right * total_right) / total_weight\n",
    "            \n",
    "            if current_entropy < entropy_min:\n",
    "                entropy_min = current_entropy\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_threshold, entropy_min\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute(x: np.ndarray, y: np.ndarray, y_probs: np.array, min_samples_leaf: int) -> tuple:\n",
    "        '''finding best threshold with gini from all attributes'''\n",
    "        best_entropy = float('inf')\n",
    "        best_threshold = None\n",
    "        best_feature = -1\n",
    "        prob_right = None\n",
    "\n",
    "        for feature_idx in range(x.shape[1]):\n",
    "            x_atr = x[:, feature_idx]\n",
    "            threshold_temp, entropy_temp = CriterionEntropy.entropy(x_atr, y, y_probs, min_samples_leaf)\n",
    "            if threshold_temp is None:\n",
    "                continue\n",
    "            if entropy_temp < best_entropy:\n",
    "                best_entropy = entropy_temp\n",
    "                best_threshold = threshold_temp\n",
    "                best_feature = feature_idx\n",
    "\n",
    "                #finding the probability of hitting the right branch\\\n",
    "                    # is necessary for future predictions\n",
    "                x_atr_complete = ~np.isnan(x_atr.astype('float'))\n",
    "                mask = x_atr_complete > best_threshold\n",
    "                prob_right = np.mean(mask)\n",
    "\n",
    "        return best_feature, best_threshold, best_entropy, prob_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node of updated decision tree\n",
    "class TreeNode:\n",
    "    def __init__(self, criterion: Criterion, depth: int, num_classes: int, min_samples_split: int = 2, min_samples_leaf: int = 1):\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.criterion = criterion\n",
    "        self.prediction = None\n",
    "        self.depth = depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.prob_right = None\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def use_criterion(self, x: np.ndarray, y: np.array, y_probs: np.array):\n",
    "        '''used to build a tree and calculate children'''\n",
    "        #the moment of stopping\n",
    "        if y.size < self.min_samples_split:\n",
    "            counts = np.bincount(y, y_probs)\n",
    "            most_frequent_index = np.argmax(counts)\n",
    "            self.prediction = y[most_frequent_index]\n",
    "            return\n",
    "        \n",
    "        #calculating threshold\n",
    "        self.feature_idx, self.threshold, _, self.prob_right = self.criterion.compute(x=x, y=y, y_probs=y_probs, min_samples_leaf=self.min_samples_leaf)\n",
    "        \n",
    "        if self.threshold is None:\n",
    "            #the moment of stopping\n",
    "            counts = np.bincount(y, y_probs)\n",
    "            most_frequent_index = np.argmax(counts)\n",
    "            self.prediction = most_frequent_index\n",
    "        else:\n",
    "            #mask for complete elements with attribute <= threshold\n",
    "            feature_col = x[:, self.feature_idx].astype(float)\n",
    "            non_nan_mask = ~np.isnan(feature_col)\n",
    "            filled_feature = np.where(non_nan_mask, feature_col, np.inf)\n",
    "            mask = non_nan_mask & (filled_feature <= self.threshold)\n",
    "            \n",
    "            #making left data with NaN elements\n",
    "            x_left = np.concatenate((x[mask], x[~non_nan_mask]))\n",
    "            y_left = np.concatenate((y[mask], y[~non_nan_mask]))\n",
    "            y_left_probs = np.concatenate((y_probs[mask], y_probs[~non_nan_mask] * self.prob_right))\n",
    "            \n",
    "            #making right data with NaN elements\n",
    "            x_right = np.concatenate((x[~mask], x[~non_nan_mask]))\n",
    "            y_right = np.concatenate((y[~mask], y[~non_nan_mask]))\n",
    "            y_right_probs = np.concatenate((y_probs[~mask], y_probs[~non_nan_mask] * (1 - self.prob_right)))\n",
    "            \n",
    "            #recursive calls to calculate children\n",
    "            self.left = TreeNode(criterion=self.criterion, depth=self.depth + 1, num_classes=self.num_classes, min_samples_split=self.min_samples_split, min_samples_leaf=self.min_samples_leaf)\n",
    "            self.left.use_criterion(x_left, y_left, y_left_probs)\n",
    "            \n",
    "            self.right = TreeNode(criterion=self.criterion, depth=self.depth + 1, num_classes=self.num_classes, min_samples_split=self.min_samples_split, min_samples_leaf=self.min_samples_leaf)\n",
    "            self.right.use_criterion(x_right, y_right, y_right_probs)\n",
    "        \n",
    "    def make_predict(self, x: np.ndarray) -> np.array:\n",
    "        '''used to predict results for x'''\n",
    "        if self.prediction is not None: \n",
    "            #it is leaf, return matrix of classes probabilities\n",
    "            probs = np.zeros((x.shape[0], self.num_classes), dtype=float)\n",
    "            probs[:, self.prediction] = 1\n",
    "            return probs\n",
    "        else:\n",
    "            #making mask for complete data with attribute >= threshold\n",
    "            feature_col = x[:, self.feature_idx].astype(float)\n",
    "            non_nan_mask = ~np.isnan(feature_col)\n",
    "            filled_feature = np.where(non_nan_mask, feature_col, -np.inf)\n",
    "            mask = non_nan_mask & (filled_feature >= self.threshold)\n",
    "            \n",
    "            indices_right = np.where(mask & non_nan_mask)[0]\n",
    "            indices_left = np.where(~mask & non_nan_mask)[0]\n",
    "            indices_nan = np.where(~non_nan_mask)[0]\n",
    "            \n",
    "            predictions_left = self.left.make_predict(x[indices_left])\n",
    "            predictions_right = self.right.make_predict(x[indices_right])\n",
    "            #making weighted predict\n",
    "            predictions_nan = self.prob_right * self.right.make_predict(x[indices_nan]) + (1 - self.prob_right) * self.left.make_predict(x[indices_nan])\n",
    "            \n",
    "            predictions = np.empty((x.shape[0], self.num_classes), dtype=int)\n",
    "            predictions[indices_left] = predictions_left\n",
    "            predictions[indices_right] = predictions_right\n",
    "            predictions[indices_nan] = predictions_nan\n",
    "            \n",
    "            return predictions\n",
    "    \n",
    "    def calculate_tree_depth(self) -> int:\n",
    "        if self.prediction is not None:\n",
    "            return self.get_depth()\n",
    "        return max(self.left.calculate_tree_depth(), self.right.calculate_tree_depth())\n",
    "    \n",
    "    def get_depth(self) -> int:\n",
    "        return self.depth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveDecisionTreeClassifier:\n",
    "   def __init__(self, criterion: str = \"gini\", min_samples_split: int = 2, min_samples_leaf: int = 1):\n",
    "      if criterion == \"gini\":\n",
    "         self.criterion = CriterionGini()\n",
    "      elif criterion == \"entropy\":\n",
    "         self.criterion = CriterionEntropy()\n",
    "      else:\n",
    "         raise ValueError(\"this criterion doesnt exist\")\n",
    "      self.min_samples_split = min_samples_split\n",
    "      self.min_samples_leaf = min_samples_leaf\n",
    "      self.head : TreeNode = None\n",
    "      self.depth = 0\n",
    "\n",
    "   def fit(self, x: np.ndarray, y: np.array) -> \"AdaptiveDecisionTreeClassifier\":\n",
    "      self.head = TreeNode(criterion=self.criterion, depth=0, num_classes=np.unique(y).size, min_samples_split=self.min_samples_split, min_samples_leaf=self.min_samples_leaf)\n",
    "      self.head.use_criterion(x, y, np.ones(y.size))\n",
    "      return self\n",
    "\n",
    "   def predict(self, x: np.ndarray) -> np.array:\n",
    "      predictions = self.head.make_predict(x)\n",
    "      return np.argmax(predictions, axis=1)\n",
    "\n",
    "   def get_depth(self) -> int:\n",
    "      return self.head.calculate_tree_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load iris dataset\n",
    "file_path = './archive/iris.csv'\n",
    "data_iris = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris_np = data_iris.to_numpy()\n",
    "x_iris = data_iris_np[:, :-1]\n",
    "y_iris = data_iris_np[:, -1]\n",
    "\n",
    "#making train and test datasets\n",
    "x_iris_train, x_iris_test, y_iris_train, y_iris_test = train_test_split(x_iris, y_iris, test_size=0.2, random_state=28)\n",
    "\n",
    "#converting the names of irises into numbers\n",
    "_, y_iris_train = np.unique(y_iris_train, return_inverse=True)\n",
    "_, y_iris_test = np.unique(y_iris_test, return_inverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сравнение с обычным деревом на полных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_clf = DecisionTreeClassifier(criterion='entropy', splitter='best', min_samples_split=2, min_samples_leaf=2, max_depth=20)\n",
    "sk_clf.fit(x_iris_train, y_iris_train)\n",
    "\n",
    "\n",
    "y_iris_pred_sk = sk_clf.predict(x_iris_test)\n",
    "sk_clf_accuracy = accuracy_score(y_iris_test, y_iris_pred_sk)\n",
    "sk_clf_f1 = f1_score(y_iris_test, y_iris_pred_sk, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_clf = AdaptiveDecisionTreeClassifier(criterion='gini', min_samples_split=2, min_samples_leaf=2)\n",
    "adaptive_clf.fit(x_iris_train, y_iris_train)\n",
    "y_iris_pred_adaptive = adaptive_clf.predict(x_iris_test)\n",
    "adaptive_clf_accuracy = accuracy_score(y_iris_test, y_iris_pred_adaptive)\n",
    "adaptive_clf_f1 = f1_score(y_iris_test, y_iris_pred_adaptive, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn accuracy = 0.9666666666666667, custom tree accuracy = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"sklearn accuracy = {sk_clf_accuracy}, custom tree accuracy = {adaptive_clf_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn f1 = 0.9666666666666667, custom tree f1 = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"sklearn f1 = {sk_clf_f1}, custom tree f1 = {adaptive_clf_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn depth = 4, custom tree depth = 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"sklearn depth = {sk_clf.get_depth()}, custom tree depth = {adaptive_clf.get_depth()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_custom_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_0  x_1  x_2  x_3  y_test  y_pred  y_custom_pred\n",
       "0   4.8  3.4  1.9  0.2       0       0              0\n",
       "1   6.1  2.6  5.6  1.4       2       2              2\n",
       "2   5.5  2.4  3.7  1.0       1       1              1\n",
       "3   5.8  4.0  1.2  0.2       0       0              0\n",
       "4   5.8  2.8  5.1  2.4       2       2              2\n",
       "5   5.0  2.3  3.3  1.0       1       1              1\n",
       "6   6.4  2.8  5.6  2.1       2       2              2\n",
       "7   5.6  3.0  4.5  1.5       1       1              1\n",
       "8   5.2  2.7  3.9  1.4       1       1              1\n",
       "9   5.0  3.2  1.2  0.2       0       0              0\n",
       "10  5.8  2.7  5.1  1.9       2       2              2\n",
       "11  5.7  4.4  1.5  0.4       0       0              0\n",
       "12  7.0  3.2  4.7  1.4       1       1              1\n",
       "13  6.4  3.2  4.5  1.5       1       1              1\n",
       "14  7.4  2.8  6.1  1.9       2       2              2\n",
       "15  5.3  3.7  1.5  0.2       0       0              0\n",
       "16  6.9  3.2  5.7  2.3       2       2              2\n",
       "17  6.7  3.3  5.7  2.1       2       2              2\n",
       "18  6.5  3.0  5.2  2.0       2       2              2\n",
       "19  6.0  2.2  4.0  1.0       1       1              1\n",
       "20  5.1  3.5  1.4  0.2       0       0              0\n",
       "21  5.5  3.5  1.3  0.2       0       0              0\n",
       "22  5.5  2.3  4.0  1.3       1       1              1\n",
       "23  5.9  3.2  4.8  1.8       1       2              2\n",
       "24  6.1  2.8  4.7  1.2       1       1              1\n",
       "25  5.0  3.3  1.4  0.2       0       0              0\n",
       "26  7.6  3.0  6.6  2.1       2       2              2\n",
       "27  6.3  3.4  5.6  2.4       2       2              2\n",
       "28  4.9  3.1  1.5  0.1       0       0              0\n",
       "29  6.9  3.1  4.9  1.5       1       1              1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"x_0\" : x_iris_test[:, 0], \"x_1\" : x_iris_test[:, 1], \"x_2\" : x_iris_test[:, 2],  \\\n",
    "    \"x_3\" : x_iris_test[:, 3],\"y_test\" : y_iris_test, \"y_pred\" : y_iris_pred_sk, \"y_custom_pred\" : y_iris_pred_adaptive})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раздел демонстрирует абсолютное совпадение результатов полученных встроенным и самостоятельно реализованным деревом на данных, не содержащих пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка данных с пропущенными атрибутами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки работы дерева на данных с пропущенными атрибутами с вероятностью 10 процентов превратим каждый атрибут тестовой и тренировочной выборок в nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(125)\n",
    "random_mask_train = np.random.random(x_iris_train.shape)\n",
    "random_mask_test = np.random.random(x_iris_test.shape)\n",
    "prob = 0.1\n",
    "x_with_nan_train = x_iris_train.copy()\n",
    "y_with_nan_train = y_iris_train.copy()\n",
    "x_with_nan_test = x_iris_test.copy()\n",
    "y_with_nan_test = y_iris_test.copy()\n",
    "x_with_nan_train[random_mask_train < prob] = np.nan\n",
    "x_with_nan_test[random_mask_test < prob] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проверка работы с пропущенными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_clf_with_nan = AdaptiveDecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf=2)\n",
    "adaptive_clf_with_nan.fit(x_with_nan_train, y_iris_train)\n",
    "y_pred_adaptive_nan = adaptive_clf_with_nan.predict(x_with_nan_test)\n",
    "accuracy_adaptive_nan = accuracy_score(y_iris_test, y_pred_adaptive_nan)\n",
    "f1_adaptive_nan = f1_score(y_iris_test, y_pred_adaptive_nan, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_adaptive_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866265664160401"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_adaptive_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_0  x_1  x_2  x_3  y_test  y_pred\n",
       "0   4.8  3.4  1.9  0.2       0       0\n",
       "1   6.1  2.6  5.6  1.4       2       1\n",
       "2   NaN  2.4  NaN  1.0       1       0\n",
       "3   5.8  4.0  NaN  0.2       0       0\n",
       "4   5.8  2.8  5.1  2.4       2       2\n",
       "5   5.0  2.3  3.3  1.0       1       1\n",
       "6   6.4  2.8  5.6  2.1       2       2\n",
       "7   5.6  3.0  4.5  1.5       1       1\n",
       "8   5.2  2.7  3.9  1.4       1       1\n",
       "9   5.0  3.2  1.2  0.2       0       0\n",
       "10  5.8  2.7  5.1  1.9       2       2\n",
       "11  5.7  4.4  1.5  0.4       0       0\n",
       "12  7.0  3.2  4.7  1.4       1       1\n",
       "13  6.4  3.2  4.5  1.5       1       1\n",
       "14  NaN  2.8  6.1  1.9       2       2\n",
       "15  5.3  3.7  1.5  0.2       0       0\n",
       "16  6.9  3.2  5.7  2.3       2       2\n",
       "17  6.7  3.3  5.7  2.1       2       2\n",
       "18  6.5  3.0  5.2  2.0       2       2\n",
       "19  6.0  2.2  4.0  1.0       1       1\n",
       "20  5.1  3.5  1.4  NaN       0       0\n",
       "21  5.5  3.5  1.3  0.2       0       0\n",
       "22  5.5  2.3  4.0  1.3       1       1\n",
       "23  5.9  3.2  4.8  NaN       1       0\n",
       "24  6.1  2.8  4.7  1.2       1       1\n",
       "25  5.0  3.3  1.4  0.2       0       0\n",
       "26  7.6  3.0  6.6  2.1       2       2\n",
       "27  NaN  3.4  5.6  2.4       2       2\n",
       "28  4.9  3.1  1.5  0.1       0       0\n",
       "29  6.9  3.1  NaN  1.5       1       0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"x_0\" : x_with_nan_test[:, 0], \"x_1\" : x_with_nan_test[:, 1], \"x_2\" : x_with_nan_test[:, 2], \\\n",
    "    \"x_3\" : x_with_nan_test[:, 3],\"y_test\" : y_with_nan_test, \"y_pred\" : y_pred_adaptive_nan})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полученного набора данных с добавлением пропусков, точность равна 86 процентам, то есть снизилась на 10 процентов по сравнению с работой дерева на тех же данных без пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
